{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Collecting openai\n",
      "  Downloading openai-1.29.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Downloading openai-1.29.0-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m320.3/320.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.29.0\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.3 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (2.6.4)\n",
      "Requirement already satisfied: tqdm in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (4.10.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.16.3)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio-1.63.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.2 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading google_generativeai-0.5.3-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.6.3-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.63.0-cp312-cp312-macosx_10_9_universal2.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, pyasn1, protobuf, httplib2, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed cachetools-5.3.3 google-ai-generativelanguage-0.6.3 google-api-core-2.19.0 google-api-python-client-2.129.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.3 googleapis-common-protos-1.63.0 grpcio-1.63.0 grpcio-status-1.62.2 httplib2-0.22.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.29.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-generativeai\n",
      "Version: 0.5.3\n",
      "Summary: Google Generative AI High level API client library and tools.\n",
      "Home-page: https://github.com/google/generative-ai-python\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages\n",
      "Requires: google-ai-generativelanguage, google-api-core, google-api-python-client, google-auth, protobuf, pydantic, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œê¸€\n"
     ]
    }
   ],
   "source": [
    "#.envëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì¼ì´ë‹¤. í•œë²ˆ ì‹¤í–‰í•˜ë©´ ì´í›„ì—ëŠ” ì‹¤í–‰í•  í•„ìš”ê°€ ì—†ë‹¤.(ì‹¤í–‰í•˜ì§€ ëª»í•œë‹¤.)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "a = os.getenv(\"HAN\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-4pXxFpf4ynFVL4PQpzXjT3BlbkFJz4a8HP8clgu30wzaFDqp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "httpìš”ì²­ì„ í†µí•œ APIë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAIì˜ GPT-3ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9OcgPO2Z8GfbvNzzrmLqWwQrNW28u', 'object': 'chat.completion', 'created': 1715655597, 'model': 'gpt-3.5-turbo-0125', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 21, 'total_tokens': 34}, 'system_fingerprint': None}\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": f\"Bearer {api_key}\",\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"ì•ˆë…•í•˜ì„¸ìš”.\"\n",
    "      }],  \n",
    "  \"temperature\": 0.2,\n",
    "  \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "response = requests.post(base_url, headers=headers, json=data)\n",
    "\n",
    "response_json = response.json()\n",
    "print(response_json)\n",
    "generated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"ì„ ì„ í•˜ê³  ìƒí¼í•œ ë´„ì˜\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "completion = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"ë´„ì— ëŒ€í•œ 1ì¤„ ë¸Œëœë”© ìŠ¬ë¡œê±´ ì‘ì„±\"  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "class DsConv2d(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=807, prompt_tokens=137, total_tokens=944)\n",
      "ë¬¼ë¡ ì´ì£ ! ì´ ì½”ë“œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë„¤íŠ¸ì›Œí¬ ì¸µ ì¤‘ í•˜ë‚˜ì¸ \"ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³± (Depthwise Separable Convolution)\" ë ˆì´ì–´ë¥¼ ì •ì˜í•œ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### í´ë˜ìŠ¤ì˜ ì •ì˜\n",
      "\n",
      "```python\n",
      "class DsConv2d(nn.Module):\n",
      "```\n",
      "`DsConv2d`ëŠ” `nn.Module`ì„ ìƒì†ë°›ì•„ ì •ì˜ëœ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ ì •ì˜í•˜ë©´ PyTorch ëª¨ë¸ì˜ ë ˆì´ì–´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### ì´ˆê¸°í™” ë©”ì†Œë“œ (`__init__`)\n",
      "\n",
      "```python\n",
      "def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
      "    super().__init__()\n",
      "```\n",
      "- `dim_in`: ì…ë ¥ ì±„ë„ ìˆ˜\n",
      "- `dim_out`: ì¶œë ¥ ì±„ë„ ìˆ˜\n",
      "- `kernel_size`: ì»¤ë„(í•„í„°)ì˜ í¬ê¸°\n",
      "- `padding`: ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ íŒ¨ë”©(padding)ì„ ì¶”ê°€í•  í¬ê¸°\n",
      "- `stride`: í•©ì„±ê³± ì—°ì‚° ì‹œì˜ ìŠ¤íŠ¸ë¼ì´ë“œ í¬ê¸° (ê¸°ë³¸ê°’ì€ 1)\n",
      "- `bias`: í•©ì„±ê³± ì—°ì‚°ì— ë°”ì´ì–´ìŠ¤ë¥¼ ì¶”ê°€í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’ì€ `True`)\n",
      "\n",
      "ì´ ì´ˆê¸°í™” ë©”ì†Œë“œì—ì„œëŠ” í´ë˜ìŠ¤ê°€ í˜¸ì¶œë  ë•Œ í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ê³ , ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ì´ˆê¸°í™” ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
      "\n",
      "### ë„¤íŠ¸ì›Œí¬ ì •ì˜\n",
      "\n",
      "```python\n",
      "self.net = nn.Sequential(\n",
      "    nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
      "    nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
      ")\n",
      "```\n",
      "ì—¬ê¸°ì—ì„œ ì‹¤ì œë¡œ ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³±ì´ ì •ì˜ë©ë‹ˆë‹¤.\n",
      "\n",
      "1. **ê¹Šì´ë³„ í•©ì„±ê³± (Depthwise Convolution)**:\n",
      "    - `nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias)`\n",
      "    - `groups = dim_in` ì¸ìë¥¼ í†µí•´ ê° ì…ë ¥ ì±„ë„ì´ ê°œë³„ì ìœ¼ë¡œ í•©ì„±ê³± ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŠ” ì±„ë„ë§ˆë‹¤ í•„í„°ê°€ ë…ë¦½ì ìœ¼ë¡œ ì ìš©ë¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì ë³„ í•©ì„±ê³± (Pointwise Convolution)**:\n",
      "    - `nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)`\n",
      "    - ì»¤ë„ í¬ê¸°ê°€ 1x1ì¸ í•©ì„±ê³±ìœ¼ë¡œ, ê° í•„í„°ê°€ ì…ë ¥ì˜ ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ê³±ì…ˆ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ ì±„ë„ì„ ì¡°í•©í•©ë‹ˆë‹¤.\n",
      "\n",
      "### ìˆœì „íŒŒ (`forward`)\n",
      "\n",
      "```python\n",
      "def forward(self, x):\n",
      "    return self.net(x)\n",
      "```\n",
      "`forward` ë©”ì†Œë“œëŠ” ì…ë ¥ ë°ì´í„° `x`ë¥¼ ë°›ì•„ ì´ ë°ì´í„°ë¥¼ `self.net`ì— ì •ì˜ëœ ì—°ì‚°(ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³±)ì„ ì ìš©í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "### ìš”ì•½\n",
      "\n",
      "- `DsConv2d` í´ë˜ìŠ¤ëŠ” ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³±ì„ êµ¬í˜„í•œ ë ˆì´ì–´ì…ë‹ˆë‹¤.\n",
      "- ì´ˆê¸°í™” ì‹œ ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, ì»¤ë„ í¬ê¸° ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
      "- `self.net`ì„ í†µí•´ ê¹Šì´ë³„ í•©ì„±ê³±ê³¼ ì ë³„ í•©ì„±ê³±ì„ ì—°ì†ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "- `forward` ë©”ì†Œë“œëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ì •ì˜ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ë³€í™˜ í›„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³±ì€ ì¼ë°˜ì ì¸ í•©ì„±ê³±ì— ë¹„í•´ ì—°ì‚° ë¹„ìš©ì„ ì¤„ì´ê³  ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ì ì—ì„œ ëª¨ë°”ì¼ í™˜ê²½ì´ë‚˜ ì œì•½ëœ ìì› í™˜ê²½ì—ì„œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-2024-05-13\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": f\"{text}\\n ì´ì½”ë“œë¥¼ ì•Œê¸°ì‰½ê²Œ ì„¤ëª…í•´ì¤„ë˜?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.usage)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¬¼ë¡ ì´ì£ ! ì´ ì½”ë“œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ë„¤íŠ¸ì›Œí¬ ì¸µ ì¤‘ í•˜ë‚˜ì¸ \"ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³± (Depthwise Separable Convolution)\" ë ˆì´ì–´ë¥¼ ì •ì˜í•œ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### í´ë˜ìŠ¤ì˜ ì •ì˜\n",
    "\n",
    "```python\n",
    "class DsConv2d(nn.Module):\n",
    "```\n",
    "`DsConv2d`ëŠ” `nn.Module`ì„ ìƒì†ë°›ì•„ ì •ì˜ëœ í´ë˜ìŠ¤ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ ì •ì˜í•˜ë©´ PyTorch ëª¨ë¸ì˜ ë ˆì´ì–´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì´ˆê¸°í™” ë©”ì†Œë“œ (`__init__`)\n",
    "\n",
    "```python\n",
    "def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "    super().__init__()\n",
    "```\n",
    "- `dim_in`: ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "- `dim_out`: ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "- `kernel_size`: ì»¤ë„(í•„í„°)ì˜ í¬ê¸°\n",
    "- `padding`: ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ íŒ¨ë”©(padding)ì„ ì¶”ê°€í•  í¬ê¸°\n",
    "- `stride`: í•©ì„±ê³± ì—°ì‚° ì‹œì˜ ìŠ¤íŠ¸ë¼ì´ë“œ í¬ê¸° (ê¸°ë³¸ê°’ì€ 1)\n",
    "- `bias`: í•©ì„±ê³± ì—°ì‚°ì— ë°”ì´ì–´ìŠ¤ë¥¼ ì¶”ê°€í• ì§€ ì—¬ë¶€ (ê¸°ë³¸ê°’ì€ `True`)\n",
    "\n",
    "ì´ ì´ˆê¸°í™” ë©”ì†Œë“œì—ì„œëŠ” í´ë˜ìŠ¤ê°€ í˜¸ì¶œë  ë•Œ í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì •ì˜í•˜ê³ , ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ì´ˆê¸°í™” ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "...\n",
    "- `self.net`ì„ í†µí•´ ê¹Šì´ë³„ í•©ì„±ê³±ê³¼ ì ë³„ í•©ì„±ê³±ì„ ì—°ì†ì ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "- `forward` ë©”ì†Œë“œëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ì•„ ì •ì˜ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ë³€í™˜ í›„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ê¹Šì´ë³„ ë¶„ë¦¬ í•©ì„±ê³±ì€ ì¼ë°˜ì ì¸ í•©ì„±ê³±ì— ë¹„í•´ ì—°ì‚° ë¹„ìš©ì„ ì¤„ì´ê³  ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ë§ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ì ì—ì„œ ëª¨ë°”ì¼ í™˜ê²½ì´ë‚˜ ì œì•½ëœ ìì› í™˜ê²½ì—ì„œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ì œì‹œëœ ì œì‹œì–´ëŠ” \"ë–¡ë³¶ì´\" ì…ë‹ˆë‹¤.\n",
      "\n",
      "\"ì—„ë§ˆê°€ ìƒê°ë‚˜\"ë¼ëŠ” ë§ì€ ì§‘ì—ì„œ ìì£¼ ë¨¹ë˜ ìŒì‹ì´ë¼ëŠ” ëœ»ì¼ ê²ƒì…ë‹ˆë‹¤. \n",
      "\n",
      "ë˜í•œ \"ìœ ëª…í•œ ë© ê°€ì‚¬ì— ë‚˜ì˜¨ë‹¤\"ëŠ” ì„¤ëª…ì€ \"ë–¡ë³¶ì´\"ë¼ëŠ” ë‹¨ì–´ê°€ í•œêµ­ ë˜í¼ ë¹„ì™€ì´(BewhY)ì˜ ë…¸ë˜ ê°€ì‚¬ì— ìì£¼ ë“±ì¥í•œë‹¤ëŠ” ê²ƒì„ ê°€ë¦¬í‚¤ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë”°ë¼ì„œ ì •ë‹µì€ \"ë–¡ë³¶ì´\"ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "system =\"\"\"\n",
    "ë¼ì´ì–´ê²Œì„ì„ í• êº¼ì•¼. ë„ˆëŠ” ë¼ì´ì–´ê³  ë‹¤ë¥¸ì‚¬ëŒë“¤ì´ ë§í•˜ëŠ”ê±¸ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ë¼ì´ì–´ë¼ëŠ” ì‚¬ì‹¤ì„ ìˆ¨ê²¨ì•¼í•´ ì–´ë–¤ ì œì‹œì–´ë¥¼ ë‹¤ë¥¸ì‚¬ëŒë“¤ì´ ì„¤ëª…í• êº¼ê³ , ì œì‹œì–´ë¥¼ ì•Œë©´ ë‹¤ë“¤ ì•Œë§Œí•œ ì„¤ëª…ì„ í•´ì¤˜ì•¼í•´\n",
    "ë„ˆëŠ” ê·¸ ì„¤ëª…ì„ ë“£ê³  ì •ë‹µì„ ìœ ì¶”í•˜ê³  ì •ë‹µê³¼ ê´€ë ¨ëœ ì„¤ëª…ì„ ë§í•´ì•¼í•´.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": \"ì£¼ì œ: ìŒì‹ \\n ì‚¬ëŒ1:ë‚˜ëŠ” ì´ê±¸ ë³´ë©´ ì—„ë§ˆê°€ ìƒê°ë‚˜ \\nì‚¬ëŒ2: ìœ ëª…í•œ ë© ê°€ì‚¬ì— ë‚˜ì™€\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::ìš°íšŒì „\n",
      "2::í¸ì˜ì  10m ì§ì§„\n",
      "3::ì¢ŒíšŒì „\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ë„¤ë¹„ê²Œì´ì…˜ ì—­í• ì„ í•´ì¤˜ íšŒì „ì´ë‚˜ ì§ì§„, í›„ì§„ ë“±ì„ 1::,2::,3:: ìœ¼ë¡œ ë‹¨ë¬¸í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜\"},\n",
    "    {\"role\": \"user\", \"content\": \"ì‚¬ê±°ë¦¬ì—ì„œ ìš°íšŒì „í•˜ê³ , í¸ì˜ì  ë³´ì´ë©´ 10m ì§ì§„í•œë‹¤ì‘ ì¢ŒíšŒì „í•˜ê¸°\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›³ï¸ğŸ’”ğŸ‘¸ğŸ¼ğŸ¤´ğŸ»ğŸŒŠğŸŒ ğŸšªğŸ”ğŸ—ï¸ğŸ’ğŸ‘«ğŸš¢â„ï¸ğŸŒ…ğŸ”ªğŸ‘©ğŸ¼â€ğŸ¦³ğŸš¢ğŸ‘‹ğŸ¼ğŸ‘‹ğŸ¼ğŸŒŠğŸ”ŠğŸ‘±ğŸ½â€â™‚ï¸ğŸŠğŸ¼â€â™‚ï¸ğŸ’”ğŸš¢ğŸŒŠâš“ï¸ğŸ’ğŸ”¥ğŸ˜­ğŸš¢ğŸš…ğŸŒ…ğŸ‘¨ğŸ¼â€ğŸ¦³ğŸš¢ğŸŒ…ğŸ’”ğŸ”ŠğŸ‘«ğŸ”ŠğŸš¿ğŸ’”ğŸ›³ï¸ğŸŒŠâœ¨ğŸ’‘ğŸŒŠğŸ’”ğŸ‘±ğŸ½â€â™€ï¸ğŸ‘©ğŸ¼ğŸš¢ğŸŒ…ğŸŒ…ğŸŒ…âœ¨ğŸ”š\n"
     ]
    }
   ],
   "source": [
    "system = \"\"\"\n",
    "You will be provided with text, and your task is to translate it into emojis. \n",
    "Do not use any regular text. Do your best with emojis only.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"ì˜í™” íƒ€ì´íƒ€ë‹‰ì˜ ì „ì²´ ìŠ¤í† ë¦¬\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "genai.configure()\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(\"hi\",  generation_config={\"temperature\": 0})\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ê·¸ë¦¼ì—ì„œ ë‚˜ì˜¤ëŠ” ë‚˜ë¬´ ì¢…ë¥˜ë¥¼ ëª¨ë‘ ì•Œ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\\nê·¸ë¦¼ì—ì„œ ë‚˜ì˜¤ëŠ” ë‚˜ë¬´ ì¢…ë¥˜ë¥¼ ì•Œë ¤ë©´ í•´ë‹¹ ì§€ì—­ì˜ ì‚°ë¦¼ì²­ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('SN_10_0041.tif')\n",
    "     \n",
    "vmodel = genai.GenerativeModel('gemini-pro-vision')\n",
    "response = vmodel.generate_content([\n",
    "    \"ê·¸ë¦¼ì—ì„œ ë‚˜ì˜¤ëŠ” ë‚˜ë¬´ ì¢…ë¥˜ë¥¼ ëª¨ë‘ ì•Œë ¤ì£¼ì„¸ìš”.\", img])\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('*.*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
