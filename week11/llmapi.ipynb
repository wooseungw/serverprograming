{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Collecting openai\n",
      "  Downloading openai-1.29.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Downloading openai-1.29.0-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.3/320.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.29.0\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.3 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pydantic in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (2.6.4)\n",
      "Requirement already satisfied: tqdm in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-generativeai) (4.10.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.16.3)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio-1.63.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.2 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.3->google-generativeai)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading google_generativeai-0.5.3-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.6.3-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.63.0-cp312-cp312-macosx_10_9_universal2.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, pyasn1, protobuf, httplib2, grpcio, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed cachetools-5.3.3 google-ai-generativelanguage-0.6.3 google-api-core-2.19.0 google-api-python-client-2.129.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.3 googleapis-common-protos-1.63.0 grpcio-1.63.0 grpcio-status-1.62.2 httplib2-0.22.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.29.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages\n",
      "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google-generativeai\n",
      "Version: 0.5.3\n",
      "Summary: Google Generative AI High level API client library and tools.\n",
      "Home-page: https://github.com/google/generative-ai-python\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: /Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages\n",
      "Requires: google-ai-generativelanguage, google-api-core, google-api-python-client, google-auth, protobuf, pydantic, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글\n"
     ]
    }
   ],
   "source": [
    "#.env는 환경변수를 저장하는 파일이다. 한번 실행하면 이후에는 실행할 필요가 없다.(실행하지 못한다.)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "a = os.getenv(\"HAN\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-4pXxFpf4ynFVL4PQpzXjT3BlbkFJz4a8HP8clgu30wzaFDqp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http요청을 통한 API를 사용하여 OpenAI의 GPT-3를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9OcgPO2Z8GfbvNzzrmLqWwQrNW28u', 'object': 'chat.completion', 'created': 1715655597, 'model': 'gpt-3.5-turbo-0125', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '안녕하세요! 무엇을 도와드릴까요?'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 21, 'total_tokens': 34}, 'system_fingerprint': None}\n",
      "안녕하세요! 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": f\"Bearer {api_key}\",\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"안녕하세요.\"\n",
    "      }],  \n",
    "  \"temperature\": 0.2,\n",
    "  \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "response = requests.post(base_url, headers=headers, json=data)\n",
    "\n",
    "response_json = response.json()\n",
    "print(response_json)\n",
    "generated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"선선하고 상큼한 봄의\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "completion = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"봄에 대한 1줄 브랜딩 슬로건 작성\"  \n",
    ")\n",
    "\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "class DsConv2d(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=807, prompt_tokens=137, total_tokens=944)\n",
      "물론이죠! 이 코드는 PyTorch를 사용하여 딥러닝 모델의 네트워크 층 중 하나인 \"깊이별 분리 합성곱 (Depthwise Separable Convolution)\" 레이어를 정의한 것입니다. 이를 쉽게 이해할 수 있도록 차근차근 설명해드리겠습니다.\n",
      "\n",
      "### 클래스의 정의\n",
      "\n",
      "```python\n",
      "class DsConv2d(nn.Module):\n",
      "```\n",
      "`DsConv2d`는 `nn.Module`을 상속받아 정의된 클래스입니다. 이렇게 정의하면 PyTorch 모델의 레이어로 사용할 수 있습니다.\n",
      "\n",
      "### 초기화 메소드 (`__init__`)\n",
      "\n",
      "```python\n",
      "def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
      "    super().__init__()\n",
      "```\n",
      "- `dim_in`: 입력 채널 수\n",
      "- `dim_out`: 출력 채널 수\n",
      "- `kernel_size`: 커널(필터)의 크기\n",
      "- `padding`: 입력 데이터에 대해 패딩(padding)을 추가할 크기\n",
      "- `stride`: 합성곱 연산 시의 스트라이드 크기 (기본값은 1)\n",
      "- `bias`: 합성곱 연산에 바이어스를 추가할지 여부 (기본값은 `True`)\n",
      "\n",
      "이 초기화 메소드에서는 클래스가 호출될 때 필요한 파라미터를 정의하고, 부모 클래스의 초기화 메소드를 호출합니다.\n",
      "\n",
      "### 네트워크 정의\n",
      "\n",
      "```python\n",
      "self.net = nn.Sequential(\n",
      "    nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias),\n",
      "    nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)\n",
      ")\n",
      "```\n",
      "여기에서 실제로 깊이별 분리 합성곱이 정의됩니다.\n",
      "\n",
      "1. **깊이별 합성곱 (Depthwise Convolution)**:\n",
      "    - `nn.Conv2d(dim_in, dim_in, kernel_size = kernel_size, padding = padding, groups = dim_in, stride = stride, bias=bias)`\n",
      "    - `groups = dim_in` 인자를 통해 각 입력 채널이 개별적으로 합성곱 연산을 수행합니다. 이는 채널마다 필터가 독립적으로 적용됨을 의미합니다.\n",
      "\n",
      "2. **점별 합성곱 (Pointwise Convolution)**:\n",
      "    - `nn.Conv2d(dim_in, dim_out, kernel_size = 1, bias = bias)`\n",
      "    - 커널 크기가 1x1인 합성곱으로, 각 필터가 입력의 모든 채널에 대해 곱셈 연산을 수행하여 채널을 조합합니다.\n",
      "\n",
      "### 순전파 (`forward`)\n",
      "\n",
      "```python\n",
      "def forward(self, x):\n",
      "    return self.net(x)\n",
      "```\n",
      "`forward` 메소드는 입력 데이터 `x`를 받아 이 데이터를 `self.net`에 정의된 연산(깊이별 분리 합성곱)을 적용합니다. 그리고 그 결과를 반환합니다.\n",
      "\n",
      "### 요약\n",
      "\n",
      "- `DsConv2d` 클래스는 깊이별 분리 합성곱을 구현한 레이어입니다.\n",
      "- 초기화 시 입력 채널 수, 출력 채널 수, 커널 크기 등을 설정합니다.\n",
      "- `self.net`을 통해 깊이별 합성곱과 점별 합성곱을 연속적으로 수행합니다.\n",
      "- `forward` 메소드는 입력 데이터를 받아 정의된 네트워크를 통해 변환 후 결과를 반환합니다.\n",
      "\n",
      "이러한 깊이별 분리 합성곱은 일반적인 합성곱에 비해 연산 비용을 줄이고 성능을 높이는 데 많이 사용됩니다. 이 점에서 모바일 환경이나 제약된 자원 환경에서 매우 유용합니다.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-2024-05-13\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": f\"{text}\\n 이코드를 알기쉽게 설명해줄래?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.usage)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론이죠! 이 코드는 PyTorch를 사용하여 딥러닝 모델의 네트워크 층 중 하나인 \"깊이별 분리 합성곱 (Depthwise Separable Convolution)\" 레이어를 정의한 것입니다. 이를 쉽게 이해할 수 있도록 차근차근 설명해드리겠습니다.\n",
    "\n",
    "### 클래스의 정의\n",
    "\n",
    "```python\n",
    "class DsConv2d(nn.Module):\n",
    "```\n",
    "`DsConv2d`는 `nn.Module`을 상속받아 정의된 클래스입니다. 이렇게 정의하면 PyTorch 모델의 레이어로 사용할 수 있습니다.\n",
    "\n",
    "### 초기화 메소드 (`__init__`)\n",
    "\n",
    "```python\n",
    "def __init__(self, dim_in, dim_out, kernel_size, padding, stride = 1, bias = True):\n",
    "    super().__init__()\n",
    "```\n",
    "- `dim_in`: 입력 채널 수\n",
    "- `dim_out`: 출력 채널 수\n",
    "- `kernel_size`: 커널(필터)의 크기\n",
    "- `padding`: 입력 데이터에 대해 패딩(padding)을 추가할 크기\n",
    "- `stride`: 합성곱 연산 시의 스트라이드 크기 (기본값은 1)\n",
    "- `bias`: 합성곱 연산에 바이어스를 추가할지 여부 (기본값은 `True`)\n",
    "\n",
    "이 초기화 메소드에서는 클래스가 호출될 때 필요한 파라미터를 정의하고, 부모 클래스의 초기화 메소드를 호출합니다.\n",
    "...\n",
    "- `self.net`을 통해 깊이별 합성곱과 점별 합성곱을 연속적으로 수행합니다.\n",
    "- `forward` 메소드는 입력 데이터를 받아 정의된 네트워크를 통해 변환 후 결과를 반환합니다.\n",
    "\n",
    "이러한 깊이별 분리 합성곱은 일반적인 합성곱에 비해 연산 비용을 줄이고 성능을 높이는 데 많이 사용됩니다. 이 점에서 모바일 환경이나 제약된 자원 환경에서 매우 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 제시된 제시어는 \"떡볶이\" 입니다.\n",
      "\n",
      "\"엄마가 생각나\"라는 말은 집에서 자주 먹던 음식이라는 뜻일 것입니다. \n",
      "\n",
      "또한 \"유명한 랩 가사에 나온다\"는 설명은 \"떡볶이\"라는 단어가 한국 래퍼 비와이(BewhY)의 노래 가사에 자주 등장한다는 것을 가리키는 것 같습니다.\n",
      "\n",
      "따라서 정답은 \"떡볶이\"입니다.\n"
     ]
    }
   ],
   "source": [
    "system =\"\"\"\n",
    "라이어게임을 할꺼야. 너는 라이어고 다른사람들이 말하는걸 바탕으로 다른 사람들에게 라이어라는 사실을 숨겨야해 어떤 제시어를 다른사람들이 설명할꺼고, 제시어를 알면 다들 알만한 설명을 해줘야해\n",
    "너는 그 설명을 듣고 정답을 유추하고 정답과 관련된 설명을 말해야해.\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": \"주제: 음식 \\n 사람1:나는 이걸 보면 엄마가 생각나 \\n사람2: 유명한 랩 가사에 나와\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::우회전\n",
      "2::편의점 10m 직진\n",
      "3::좌회전\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"너는 네비게이션 역할을 해줘 회전이나 직진, 후진 등을 1::,2::,3:: 으로 단문형식으로 알려줘\"},\n",
    "    {\"role\": \"user\", \"content\": \"사거리에서 우회전하고, 편의점 보이면 10m 직진한다응 좌회전하기\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛳️💔👸🏼🤴🏻🌊🌠🚪🔐🗝️💏👫🚢❄️🌅🔪👩🏼‍🦳🚢👋🏼👋🏼🌊🔊👱🏽‍♂️🏊🏼‍♂️💔🚢🌊⚓️💏🔥😭🚢🚅🌅👨🏼‍🦳🚢🌅💔🔊👫🔊🚿💔🛳️🌊✨💑🌊💔👱🏽‍♀️👩🏼🚢🌅🌅🌅✨🔚\n"
     ]
    }
   ],
   "source": [
    "system = \"\"\"\n",
    "You will be provided with text, and your task is to translate it into emojis. \n",
    "Do not use any regular text. Do your best with emojis only.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"영화 타이타닉의 전체 스토리\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/pyserverprog/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "genai.configure()\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(\"hi\",  generation_config={\"temperature\": 0})\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 그림에서 나오는 나무 종류를 모두 알 수는 없습니다.\\n그림에서 나오는 나무 종류를 알려면 해당 지역의 산림청에 문의하시기 바랍니다.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('SN_10_0041.tif')\n",
    "     \n",
    "vmodel = genai.GenerativeModel('gemini-pro-vision')\n",
    "response = vmodel.generate_content([\n",
    "    \"그림에서 나오는 나무 종류를 모두 알려주세요.\", img])\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('*.*')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
